{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MhT8EjA5yGq"
      },
      "source": [
        "1. Здесь идет установка **необходимых библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFzSvVq6k1hL",
        "outputId": "2dcdf0b5-b5b7-498f-c861-1c814cae45c7"
      },
      "outputs": [],
      "source": [
        "!pip3 install pydub\n",
        "!pip3 install vosk\n",
        "!pip3 install torch\n",
        "!pip3 install transformers\n",
        "!git clone https://git.ffmpeg.org/ffmpeg.git ffmpeg\n",
        "%pip install moviepy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-R2yJvt6A5C"
      },
      "source": [
        "1.2 Vosk model installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_RjMT8lwdZ",
        "outputId": "3503b1a3-7d39-420b-e90e-9bad7a0c291a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1847M  100 1847M    0     0  3046k      0  0:10:21  0:10:21 --:--:-- 3121k 0  3018k      0  0:10:26  0:00:25  0:10:01 3596k8:05 5770k0  0:06:02  0:02:29  0:03:33 4688k   0  4887k      0  0:06:27  0:03:19  0:03:08 4098k    0  4214k      0  0:07:28  0:04:49  0:02:39 1851k  0     0  3658k      0  0:08:37  0:06:45  0:01:52 2032k   0     0  3519k      0  0:08:57  0:07:20  0:01:37 1570k05  0:07:33  0:01:32 1977k     0  3114k      0  0:10:07  0:09:22  0:00:45 1170k\n",
            "Archive:  model.zip\n",
            "   creating: vosk-model-ru-0.42/\n",
            "   creating: vosk-model-ru-0.42/graph/\n",
            "  inflating: vosk-model-ru-0.42/graph/words.txt  \n",
            "   creating: vosk-model-ru-0.42/graph/phones/\n",
            " extracting: vosk-model-ru-0.42/graph/phones/silence.csl  \n",
            "  inflating: vosk-model-ru-0.42/graph/phones/align_lexicon.txt  \n",
            "  inflating: vosk-model-ru-0.42/graph/phones/word_boundary.txt  \n",
            " extracting: vosk-model-ru-0.42/graph/phones/optional_silence.csl  \n",
            " extracting: vosk-model-ru-0.42/graph/phones/optional_silence.txt  \n",
            "  inflating: vosk-model-ru-0.42/graph/phones/disambig.int  \n",
            " extracting: vosk-model-ru-0.42/graph/phones/disambig.txt  \n",
            "  inflating: vosk-model-ru-0.42/graph/phones/align_lexicon.int  \n",
            "  inflating: vosk-model-ru-0.42/graph/phones/word_boundary.int  \n",
            " extracting: vosk-model-ru-0.42/graph/phones/optional_silence.int  \n",
            "  inflating: vosk-model-ru-0.42/graph/phones.txt  \n",
            "  inflating: vosk-model-ru-0.42/graph/HCLG.fst  \n",
            " extracting: vosk-model-ru-0.42/graph/num_pdfs  \n",
            "  inflating: vosk-model-ru-0.42/graph/disambig_tid.int  \n",
            "  inflating: vosk-model-ru-0.42/decode.py  \n",
            "   creating: vosk-model-ru-0.42/am/\n",
            " extracting: vosk-model-ru-0.42/am/frame_subsampling_factor  \n",
            "  inflating: vosk-model-ru-0.42/am/tree  \n",
            "  inflating: vosk-model-ru-0.42/am/final.mdl  \n",
            "   creating: vosk-model-ru-0.42/extra/\n",
            "  inflating: vosk-model-ru-0.42/extra/sova_devices.ref  \n",
            "  inflating: vosk-model-ru-0.42/extra/silero_youtube.ref  \n",
            "  inflating: vosk-model-ru-0.42/extra/golos_crowd.ref  \n",
            "  inflating: vosk-model-ru-0.42/extra/README  \n",
            "  inflating: vosk-model-ru-0.42/extra/silero_books.ref  \n",
            "  inflating: vosk-model-ru-0.42/extra/silero_calls.ref  \n",
            "   creating: vosk-model-ru-0.42/rnnlm/\n",
            " extracting: vosk-model-ru-0.42/rnnlm/oov.txt  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/special_symbol_opts.conf  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/unigram_probs.txt  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/features.txt  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/final.raw  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/special_symbol_opts.txt  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/feat_embedding.final.mat  \n",
            "  inflating: vosk-model-ru-0.42/rnnlm/word_feats.txt  \n",
            "  inflating: vosk-model-ru-0.42/decoder-test.wav  \n",
            "  inflating: vosk-model-ru-0.42/README  \n",
            "   creating: vosk-model-ru-0.42/rescore/\n",
            "  inflating: vosk-model-ru-0.42/rescore/G.fst  \n",
            "  inflating: vosk-model-ru-0.42/rescore/G.carpa  \n",
            "   creating: vosk-model-ru-0.42/conf/\n",
            "  inflating: vosk-model-ru-0.42/conf/model.conf  \n",
            "  inflating: vosk-model-ru-0.42/conf/ivector_extractor.conf  \n",
            "  inflating: vosk-model-ru-0.42/conf/mfcc.conf  \n",
            "  inflating: vosk-model-ru-0.42/conf/online.conf  \n",
            "   creating: vosk-model-ru-0.42/ivector/\n",
            "  inflating: vosk-model-ru-0.42/ivector/final.dubm  \n",
            "  inflating: vosk-model-ru-0.42/ivector/global_cmvn.stats  \n",
            "  inflating: vosk-model-ru-0.42/ivector/final.ie  \n",
            "  inflating: vosk-model-ru-0.42/ivector/final.mat  \n",
            "  inflating: vosk-model-ru-0.42/ivector/splice.conf  \n",
            " extracting: vosk-model-ru-0.42/ivector/online_cmvn.conf  \n"
          ]
        }
      ],
      "source": [
        "!curl -o ./model.zip https://alphacephei.com/vosk/models/vosk-model-ru-0.42.zip\n",
        "!unzip model.zip\n",
        "!mv vosk-model-ru-0.42/ model\n",
        "!rm -rf model.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiEOFoSx6Paq"
      },
      "source": [
        "This model can be put to VOSK, but its use takes too much resources of the computer itself. Deals with punctuation marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RmaA7idmOaS",
        "outputId": "57a9b875-2d0b-4577-e5f0-248e18176330"
      },
      "outputs": [],
      "source": [
        "!curl -o recasepunc.zip https://alphacephei.com/vosk/models/vosk-recasepunc-ru-0.22.zip\n",
        "!unzip recasepunc.zip\n",
        "!mv vosk-recasepunc-ru-0.22/ recasepunc\n",
        "!rm -rf recasepunc.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'recasepunc' already exists and is not an empty directory.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting git+https://github.com/benob/mosestokenizer.git (from -r ./recasepunc/requirements.txt (line 1))\n",
            "  Cloning https://github.com/benob/mosestokenizer.git to /tmp/pip-req-build-k83wezdf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/benob/mosestokenizer.git /tmp/pip-req-build-k83wezdf\n",
            "  Resolved https://github.com/benob/mosestokenizer.git to commit 169bd3a504fe20a3e51b9a7af3f0ca359c2d36c9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting numpy==1.19.5 (from -r ./recasepunc/requirements.txt (line 2))\n",
            "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting regex==2021.8.28 (from -r ./recasepunc/requirements.txt (line 3))\n",
            "  Using cached regex-2021.8.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (39 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu111 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/benob/recasepunc\n",
        "!pip3 install -r ./recasepunc/requirements.txt -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7Ua2SIvqk8EQ"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "import json\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy.video.io.html_tools import ffmpeg_parse_infos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP1rydn6rzmU",
        "outputId": "7277e1b4-70da-4310-bc6d-28eaffc49196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in file.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "def convert_mp4_to_wav(input_file, output_file):\n",
        "    video = VideoFileClip(input_file)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(output_file)\n",
        "\n",
        "input_file = 'video.mp4'\n",
        "output_file = 'file.wav'\n",
        "convert_mp4_to_wav(input_file, output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xUGrxfRtlCCf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
            "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
            "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
            "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from model/ivector/final.ie\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from model/graph/HCLG.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:297) Loading words from model/graph/words.txt\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo model/graph/phones/word_boundary.int\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:315) Loading subtract G.fst model from model/rescore/G.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:317) Loading CARPA model from model/rescore/G.carpa\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:323) Loading RNNLM model from model/rnnlm/final.raw\n"
          ]
        }
      ],
      "source": [
        "#SetLogLevel(0)\n",
        "import os\n",
        "# checking model\n",
        "if not os.path.exists(\"model\"):\n",
        "    print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n",
        "    exit (1)\n",
        "\n",
        "# set Frame Rate\n",
        "FRAME_RATE = 16000\n",
        "CHANNELS=1\n",
        "\n",
        "model = Model(\"model\")\n",
        "rec = KaldiRecognizer(model, FRAME_RATE)\n",
        "rec.SetWords(True)\n",
        "\n",
        "# Используя библиотеку pydub делаем предобработку аудио\n",
        "mp3 = AudioSegment.from_mp3('file.wav')\n",
        "mp3 = mp3.set_channels(CHANNELS)\n",
        "mp3 = mp3.set_frame_rate(FRAME_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjBoYZJJXrgh"
      },
      "outputs": [],
      "source": [
        "# Преобразуем вывод в json\n",
        "rec.AcceptWaveform(mp3.raw_data)\n",
        "result = rec.Result()\n",
        "text = json.loads(result)[\"text\"]\n",
        "\n",
        "# Добавляем пунктуацию (Занимает очень много ресурсов, можно и без нее)\n",
        "#cased = subprocess.check_output('python3 recasepunc/recasepunc.py predict recasepunc/checkpoint', shell=True, text=True, input=text)\n",
        "# Записываем результат в файл \"data.txt\"\n",
        "with open('ff.txt', 'w') as f:\n",
        "    json.dump(text, f, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "from torch import package\n",
        "\n",
        "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
        "                               'latest_silero_models.yml',\n",
        "                               progress=False)\n",
        "\n",
        "with open('latest_silero_models.yml', 'r') as yaml_file:\n",
        "    models = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
        "model_conf = models.get('te_models').get('latest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# see avaiable languages\n",
        "available_languages = list(model_conf.get('languages'))\n",
        "print(f'Available languages {available_languages}')\n",
        "\n",
        "# and punctuation marks\n",
        "available_punct = list(model_conf.get('punct'))\n",
        "print(f'Available punctuation marks {available_punct}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_url = model_conf.get('package')\n",
        "\n",
        "model_dir = \"downloaded_model\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "model_path = os.path.join(model_dir, os.path.basename(model_url))\n",
        "\n",
        "if not os.path.isfile(model_path):\n",
        "    torch.hub.download_url_to_file(model_url,\n",
        "                                   model_path,\n",
        "                                   progress=True)\n",
        "\n",
        "imp = package.PackageImporter(model_path)\n",
        "model = imp.load_pickle(\"te_model\", \"model\")\n",
        "example_texts = model.examples\n",
        "\n",
        "def apply_te(text, lan='ru'):\n",
        "    return model.enhance_text(text, lan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text = model.examples[0]\n",
        "output_text = apply_te(input_text, lan='ru')\n",
        "print(f\"Input: \\n{input_text}\\nOutput:\\n{output_text}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('ff.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "    \n",
        "#input_text = input('Enter input text\\n')\n",
        "print(apply_te(input_text, lan='ru'))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
